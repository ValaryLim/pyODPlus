{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# generate data\n",
    "from utils.data_generator import generate_synthetic_clusters, generate_synthetic_d1, \\\n",
    "    generate_synthetic_d2, generate_synthetic_d3\n",
    "\n",
    "# for outlier detection\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.knn import KNN\n",
    "from outlier_detection.rocf import ROCF # import ROCF\n",
    "from outlier_detection.cbof import CBOF\n",
    "\n",
    "# for evaluation\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# exploratory data analysis\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# bayesian hyperparameter optimization\n",
    "from hyperopt import hp, Trials, fmin, tpe, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "from time import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Dataset D1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_d1, y_d1 = generate_synthetic_d1()\n",
    "color_d1 = [\"red\" if i == 1 else \"black\" for i in y_d1]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter([x[0] for x in X_d1], [x[1] for x in X_d1], c=color_d1, s=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate Parameters Suggested in Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model functions\n",
    "n_samples = len(y_d1)\n",
    "\n",
    "# dictionary of models & parameters to test\n",
    "# LOF, CBOF, ROCF are replications of Table 1 of the paper\n",
    "functions_dict = {\n",
    "    'LOF (k=10, n=10)': { 'algo': 'LOF', 'k':10, 'n':10, 'f':LOF(n_neighbors=10, contamination=30/n_samples) }, \n",
    "    'LOF (k=10, n=20)': { 'algo': 'LOF', 'k':10, 'n':20, 'f':LOF(n_neighbors=10, contamination=45/n_samples) },\n",
    "    'LOF (k=10, n=30)': { 'algo': 'LOF', 'k':10, 'n':30, 'f':LOF(n_neighbors=10, contamination=60/n_samples) },\n",
    "    'CBOF (k=6, alpha=0.95)': {'algo': 'CBOF', 'k': 6, 'n':83, 'f':CBOF(k=6, contamination=0.05, pct=0.3, lofub=1) },\n",
    "    'CBOF (k=6, alpha=0.90)': {'algo': 'CBOF', 'k': 6, 'n':165, 'f':CBOF(k=6, contamination=0.10, pct=0.3, lofub=1) },\n",
    "    'CBOF (k=6, alpha=0.85)': {'algo': 'CBOF', 'k': 6, 'n':248, 'f':CBOF(k=6, contamination=0.15, pct=0.3, lofub=1) },\n",
    "    'ROCF (k=4)': { 'algo': 'ROCF', 'k':4, 'n':None, 'f':ROCF(distance_metric=\"euclidean\", k=4) }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output dataframe\n",
    "d1_results = pd.DataFrame(columns=['algo', 'k', 'n', 'outlier_rate', 'recall', 'precision', 'f1'])\n",
    "\n",
    "for name, f_dict in tqdm(functions_dict.items()):\n",
    "    # initialise classifier\n",
    "    clf = f_dict['f']\n",
    "\n",
    "    # fit classifier on data\n",
    "    clf.fit(X_d1)\n",
    "\n",
    "    # retrieve predictions\n",
    "    try:\n",
    "        y_pred = clf.get_outliers()\n",
    "    except:\n",
    "        y_pred = clf.labels_\n",
    "\n",
    "\n",
    "    # derive evaluation metrics\n",
    "    report = classification_report(y_true=y_d1, y_pred=y_pred, output_dict=True)['1']\n",
    "\n",
    "    row = { \n",
    "        'algo': f_dict['algo'], 'k': f_dict['k'], 'n': f_dict['n'],\n",
    "        'precision': report['precision'], 'recall': report['recall'], 'f1': report['f1-score']\n",
    "    }\n",
    "\n",
    "    # retrieve outlier rate\n",
    "    try:\n",
    "        row['outlier_rate'] = clf.get_outlier_rate()\n",
    "    except:\n",
    "        row['outlier_rate'] = clf.contamination\n",
    "\n",
    "    d1_results = d1_results.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print results\n",
    "d1_results[[\"algo\", \"outlier_rate\", \"recall\", \"precision\", \"f1\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt(param_space, X, y, num_eval, classifier):  \n",
    "    '''\n",
    "    Function that performs Bayesian hyperparameter optimisation \n",
    "    to find the optimal parameters for the outlier detection algorithm.\n",
    "    \n",
    "    Inputs:\n",
    "        param_space (dict): A dictionary of the parameters and corresponding space to search.\n",
    "        X (array): Features of the dataset.\n",
    "        y (array): Labels of the dataset (0 = normal; 1 = anomaly).\n",
    "        \n",
    "        num_eval (int): Number of evaluation rounds.\n",
    "        classifier (pyOD Object): Outlier detection algorithm.\n",
    "        \n",
    "    Outputs:\n",
    "        trials\n",
    "        -min(loss) (float): Best in-sample F1 score.\n",
    "        best_param_values (dict): Dictionary of the best parameters for the classifier.\n",
    "    '''\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    def objective_function(params):\n",
    "        # initialise classifier\n",
    "        clf = classifier(**params)\n",
    "        # fit data\n",
    "        clf.fit(X)\n",
    "        # predict\n",
    "        try:\n",
    "            y_pred = clf.predict(X)\n",
    "        except: # ROCF algorithm\n",
    "            y_pred = clf.get_outliers()\n",
    "        # get F1 score\n",
    "        report = classification_report(y_true=y, y_pred=y_pred, output_dict=True)['1']\n",
    "        # objective is to maximize F1 i.e. minimize -F1\n",
    "        return {'status': STATUS_OK, 'loss': -report['f1-score'], 'precision': report['precision'], \n",
    "                'recall': report['recall']}\n",
    "    \n",
    "    trials = Trials()\n",
    "    \n",
    "    # minimise objective function\n",
    "    best_param = fmin(objective_function, param_space, algo=tpe.suggest, max_evals=num_eval, \n",
    "                      trials=trials, rstate= np.random.RandomState(1))\n",
    "    \n",
    "    loss = [x['result']['loss'] for x in trials.trials] \n",
    "    precision = [x['result']['precision'] for x in trials.trials] \n",
    "    recall = [x['result']['recall'] for x in trials.trials] \n",
    "    \n",
    "    best_ind = loss.index(min(loss))\n",
    "    \n",
    "    best_param_values = best_param\n",
    "    \n",
    "    return trials, -loss[best_ind], best_param_values, precision[best_ind], recall[best_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict to store hyperopt inputs for each algorithm\n",
    "hyperopt_inputs = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter search range\n",
    "LOF_param_hyperopt = {\n",
    "    'n_neighbors': scope.int(hp.quniform('n_neighbors', 5, 15, 1)), \n",
    "    'algorithm': hp.choice('algorithm', ['ball_tree', 'kd_tree', 'brute']),\n",
    "    'leaf_size': scope.int(hp.quniform('leaf_size', 25, 35, 1)),\n",
    "    'contamination': 45/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "# num_eval proportional to number of combinations of parameter values for different models\n",
    "# num_eval = 3*(num_params_to_tune)\n",
    "LOF_inputs = {'classifier': LOF, 'param_space': LOF_param_hyperopt, 'num_eval': 3**3}\n",
    "hyperopt_inputs['LOF'] = LOF_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Based Outlier Factor (CBOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter search range\n",
    "CBOF_param_hyperopt = {\n",
    "    'k': scope.int(hp.quniform('n_neighbors', 2, 10, 1)),\n",
    "    'lofub': hp.uniform('lofub', 0.5, 5.0),\n",
    "    'pct': hp.uniform('pct', 0.2, 0.8),\n",
    "    'contamination': 45/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "CBOF_inputs = {'classifier': CBOF, 'param_space': CBOF_param_hyperopt, 'num_eval': 3**3}\n",
    "hyperopt_inputs['CBOF'] = CBOF_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Outlier Cluster Factor (ROCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROCF_param_hyperopt = {\n",
    "    'k': scope.int(hp.quniform('n_neighbors', 2, 10, 1))\n",
    "}\n",
    "\n",
    "ROCF_inputs = {'classifier': ROCF, 'param_space': ROCF_param_hyperopt, 'num_eval': 3**1}\n",
    "hyperopt_inputs['ROCF'] = ROCF_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_param_hyperopt = {\n",
    "    'n_neighbors': scope.int(hp.quniform('n_neighbors', 2, 15, 1)),\n",
    "    'method': hp.choice('method', ['largest', 'mean', 'median']),\n",
    "    'contamination': 45/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "KNN_inputs = {'classifier': KNN, 'param_space': KNN_param_hyperopt, 'num_eval': 3**2}\n",
    "hyperopt_inputs['KNN'] = KNN_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest (IForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IF_param_hyperopt = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 3, 20, 1)),\n",
    "    'max_samples': scope.int(hp.quniform('max_samples', 10, 20, 1)),    \n",
    "    'max_features': 2, # since X has only 2 features, set it to 2\n",
    "    'contamination': 45/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "IF_inputs = {'classifier': IForest, 'param_space': IF_param_hyperopt, 'num_eval': 3**3}\n",
    "hyperopt_inputs['IForest'] = IF_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Class Support Vector Machine (OCSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCSVM_param_hyperopt = {\n",
    "    'kernel': hp.choice('kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'nu': hp.uniform('nu', 0.1, 0.9),\n",
    "    'contamination': 45/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "OCSVM_inputs = {'classifier': OCSVM, 'param_space': OCSVM_param_hyperopt, 'num_eval': 3**2}\n",
    "hyperopt_inputs['OCSVM'] = OCSVM_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_results_tuned = pd.DataFrame(columns=['algo', 'f1', 'precision', 'recall'])\n",
    "\n",
    "for algo, algo_inputs in hyperopt_inputs.items():\n",
    "    # run hyperopt\n",
    "    algo_hyperopt = hyperopt(algo_inputs['param_space'], \\\n",
    "                             X_d1, y_d1, \\\n",
    "                             algo_inputs['num_eval'], algo_inputs['classifier'])\n",
    "    # retrieve best parameters\n",
    "    algo_opt = algo_hyperopt[2]\n",
    "    algo_opt['f1'] = algo_hyperopt[1] # add f1 score\n",
    "    algo_opt['precision'] = algo_hyperopt[3]\n",
    "    algo_opt['recall'] = algo_hyperopt[4]\n",
    "    algo_opt['algo'] = algo # add algo name\n",
    "    # add to results dataframe\n",
    "    d1_results_tuned = d1_results_tuned.append(algo_opt, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d1_results_tuned[[\"algo\", \"recall\", \"precision\", \"f1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_results_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results with Tuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve float parameters\n",
    "cbof_lofub = d1_results_tuned.loc[1,\"lofub\"]\n",
    "cbof_pct = d1_results_tuned.loc[1,\"pct\"]\n",
    "OCSVM_nu = d1_results_tuned.loc[5,\"nu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model functions\n",
    "n_samples = len(y_d1)\n",
    "\n",
    "# dictionary of models & parameters to test\n",
    "# LOF, CBOF, ROCF are replications of Table 3 of the paper\n",
    "functions_dict = {\n",
    "    # LOF\n",
    "    'LOF (n=30)': { 'algo':'LOF', 'f':LOF(n_neighbors=9, algorithm=\"kd_tree\", leaf_size=30,\n",
    "                                          contamination=30/n_samples) }, \n",
    "    'LOF (n=45)': { 'algo':'LOF', 'f':LOF(n_neighbors=9, algorithm=\"kd_tree\", leaf_size=30,\n",
    "                                          contamination=45/n_samples) }, \n",
    "    'LOF (n=60)': { 'algo':'LOF', 'f':LOF(n_neighbors=9, algorithm=\"kd_tree\", leaf_size=30,\n",
    "                                           contamination=60/n_samples) },\n",
    "    \n",
    "    # CBOF\n",
    "    'CBOF (n=30)': { 'algo':'CBOF', 'f':CBOF(k=5, pct=cbof_pct, lofub=cbof_lofub, contamination=30/n_samples) },\n",
    "    'CBOF (n=45)': { 'algo':'CBOF', 'f':CBOF(k=5, pct=cbof_pct, lofub=cbof_lofub, contamination=45/n_samples, ) },\n",
    "    'CBOF (n=60)': { 'algo':'CBOF', 'f':CBOF(k=5, pct=cbof_pct, lofub=cbof_lofub, contamination=60/n_samples) },\n",
    "    \n",
    "    # ROCF\n",
    "    'ROCF': { 'algo': 'ROCF', 'f':ROCF(distance_metric=\"euclidean\", k=4) },\n",
    "    \n",
    "    # KNN\n",
    "    'KNN (n=30)': { 'algo': 'KNN', 'f':KNN(method=\"largest\", n_neighbors=5, contamination=30/n_samples) },\n",
    "    'KNN (n=45)': { 'algo': 'KNN', 'f':KNN(method=\"largest\", n_neighbors=5, contamination=45/n_samples) },\n",
    "    'KNN (n=60)': { 'algo': 'KNN', 'f':KNN(method=\"largest\", n_neighbors=5, contamination=60/n_samples) },\n",
    "    \n",
    "    # IFOREST\n",
    "    'IForest (n=30)': { 'algo': 'IForest', 'f':IForest(max_samples=15, n_estimators=15, \n",
    "                                                       contamination=30/n_samples) },\n",
    "    'IForest (n=45)': { 'algo': 'IForest', 'f':IForest(max_samples=15, n_estimators=15,\n",
    "                                                       contamination=45/n_samples) },\n",
    "    'IForest (n=60)': { 'algo': 'IForest', 'f':IForest(max_samples=15, n_estimators=15, \n",
    "                                                        contamination=60/n_samples) },\n",
    "    \n",
    "    # OCSVM\n",
    "    'OCSVM (n=30)': { 'algo': 'OCSVM', 'f':OCSVM(kernel=\"rbf\", nu=OCSVM_nu, contamination=30/n_samples) },\n",
    "    'OCSVM (n=45)': { 'algo': 'OCSVM', 'f':OCSVM(kernel=\"rbf\", nu=OCSVM_nu, contamination=45/n_samples) },\n",
    "    'OCSVM (n=60)': { 'algo': 'OCSVM', 'f':OCSVM(kernel=\"rbf\", nu=OCSVM_nu, contamination=60/n_samples) },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output dataframe\n",
    "d1_final_results = pd.DataFrame(columns=['algo', 'outlier_rate', 'recall', 'precision', 'f1'])\n",
    "\n",
    "for name, f_dict in tqdm(functions_dict.items()):\n",
    "    # initialise classifier\n",
    "    clf = f_dict['f']\n",
    "\n",
    "    # fit classifier on data\n",
    "    clf.fit(X_d1)\n",
    "\n",
    "    # retrieve predictions\n",
    "    try:\n",
    "        y_pred = clf.get_outliers()\n",
    "    except:\n",
    "        y_pred = clf.labels_\n",
    "\n",
    "\n",
    "    # derive evaluation metrics\n",
    "    report = classification_report(y_true=y_d1, y_pred=y_pred, output_dict=True)['1']\n",
    "\n",
    "    row = { \n",
    "        'algo': f_dict['algo'], \n",
    "        'precision': report['precision'], 'recall': report['recall'], 'f1': report['f1-score']\n",
    "    }\n",
    "\n",
    "    # retrieve outlier rate\n",
    "    try:\n",
    "        row['outlier_rate'] = clf.get_outlier_rate()\n",
    "    except:\n",
    "        row['outlier_rate'] = clf.contamination\n",
    "\n",
    "    d1_final_results = d1_final_results.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Max ROCF from Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocf = ROCF(distance_metric=\"euclidean\", k=4)\n",
    "rocf.fit(X_d1)\n",
    "max_rocf = max(rocf.get_rocfs())\n",
    "print(max_rocf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Specification of Parameter k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_f1score = []\n",
    "k_value = []\n",
    "for k in tqdm(range(1, 31)):\n",
    "    # run rocf\n",
    "    rocf = ROCF(distance_metric=\"euclidean\", k=k)\n",
    "    \n",
    "    # fit rocf\n",
    "    rocf.fit(X_d1)\n",
    "    \n",
    "    # retrieve predictions\n",
    "    y_pred = rocf.get_outliers()\n",
    "\n",
    "    # derive evaluation metrics\n",
    "    report = classification_report(y_true=y_d1, y_pred=y_pred, output_dict=True)['1']\n",
    "    k_f1score.append(report[\"f1-score\"])\n",
    "    k_value.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(k_value, k_f1score, marker=\".\", color=\"darkblue\")\n",
    "plt.title('F1 Score against k (D1 dataset)')\n",
    "plt.xlabel('k, number of nearest neighbors')\n",
    "plt.ylabel('F1 Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Dataset D2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_d2, y_d2 = generate_synthetic_d2()\n",
    "color_d2 = [\"red\" if i == 1 else \"black\" for i in y_d2]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter([x[0] for x in X_d2], [x[1] for x in X_d2], c=color_d2, s=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate Parameters Suggested in Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model functions\n",
    "n_samples = len(y_d2)\n",
    "\n",
    "# dictionary of models & parameters to test\n",
    "# LOF, CBOF, ROCF are replications of Table 2 of the paper\n",
    "functions_dict = {\n",
    "    'LOF (k=15, n=50)': { 'algo': 'LOF', 'k':15, 'n':50, 'f':LOF(n_neighbors=15, contamination=50/n_samples) }, \n",
    "    'LOF (k=15, n=79)': { 'algo': 'LOF', 'k':15, 'n':79, 'f':LOF(n_neighbors=15, contamination=79/n_samples) },\n",
    "    'LOF (k=15, n=100)': { 'algo': 'LOF', 'k':15, 'n':100, 'f':LOF(n_neighbors=15, contamination=100/n_samples) },\n",
    "    'CBOF (k=15, alpha=0.95)': {'algo': 'CBOF', 'k': 15, 'n':54, 'f':CBOF(k=15, contamination=0.05, pct=0.2, lofub=1) },\n",
    "    'CBOF (k=15, alpha=0.90)': {'algo': 'CBOF', 'k': 15, 'n':108, 'f':CBOF(k=15, contamination=0.10, pct=0.2, lofub=1) },\n",
    "    'CBOF (k=15, alpha=0.85)': {'algo': 'CBOF', 'k': 15, 'n':162, 'f':CBOF(k=15, contamination=0.15, pct=0.2, lofub=1) },\n",
    "    'ROCF (k=10)': { 'algo': 'ROCF', 'k':10, 'n':None, 'f':ROCF(distance_metric=\"euclidean\", k=10) }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output dataframe\n",
    "d2_results = pd.DataFrame(columns=['algo', 'k', 'n', 'outlier_rate', 'recall', 'precision', 'f1'])\n",
    "\n",
    "for name, f_dict in tqdm(functions_dict.items()):\n",
    "    # initialise classifier\n",
    "    clf = f_dict['f']\n",
    "\n",
    "    # fit classifier on data\n",
    "    clf.fit(X_d2)\n",
    "\n",
    "    # retrieve predictions\n",
    "    try:\n",
    "        y_pred = clf.get_outliers()\n",
    "    except:\n",
    "        y_pred = clf.labels_\n",
    "\n",
    "\n",
    "    # derive evaluation metrics\n",
    "    report = classification_report(y_true=y_d2, y_pred=y_pred, output_dict=True)['1']\n",
    "\n",
    "    row = { \n",
    "        'algo': f_dict['algo'], 'k': f_dict['k'], 'n': f_dict['n'],\n",
    "        'precision': report['precision'], 'recall': report['recall'], 'f1': report['f1-score']\n",
    "    }\n",
    "\n",
    "    # retrieve outlier rate\n",
    "    try:\n",
    "        row['outlier_rate'] = clf.get_outlier_rate()\n",
    "    except:\n",
    "        row['outlier_rate'] = clf.contamination\n",
    "\n",
    "    d2_results = d2_results.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_results[[\"algo\", \"outlier_rate\", \"recall\", \"precision\", \"f1\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hyperopt_inputs = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define parameter search range\n",
    "LOF_param_hyperopt = {\n",
    "    'n_neighbors': scope.int(hp.quniform('n_neighbors', 10, 20, 1)), \n",
    "    'algorithm': hp.choice('algorithm', ['ball_tree', 'kd_tree', 'brute']),\n",
    "    'leaf_size': scope.int(hp.quniform('leaf_size', 20, 40, 1)),\n",
    "    'contamination': 79/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "# num_eval proportional to number of combinations of parameter values for different models\n",
    "# num_eval = 3*(num_params_to_tune)\n",
    "LOF_inputs = {'classifier': LOF, 'param_space': LOF_param_hyperopt, 'num_eval': 3**3}\n",
    "hyperopt_inputs['LOF'] = LOF_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cluster Based Outlier Factor (CBOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define parameter search range\n",
    "CBOF_param_hyperopt = {\n",
    "    'k': scope.int(hp.quniform('n_neighbors', 10, 20, 1)),\n",
    "    'lofub': hp.uniform('lofub', 0.5, 5.0),\n",
    "    'pct': hp.uniform('pct', 0.2, 0.8),\n",
    "    'contamination': 79/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "CBOF_inputs = {'classifier': CBOF, 'param_space': CBOF_param_hyperopt, 'num_eval': 3**3}\n",
    "hyperopt_inputs['CBOF'] = CBOF_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Relative Outlier Cluster Factor (ROCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define parameter search range\n",
    "ROCF_param_hyperopt = {\n",
    "    'k': scope.int(hp.quniform('n_neighbors', 5, 15, 1))\n",
    "}\n",
    "\n",
    "ROCF_inputs = {'classifier': ROCF, 'param_space': ROCF_param_hyperopt, 'num_eval': 3**1}\n",
    "hyperopt_inputs['ROCF'] = ROCF_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### k-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "KNN_param_hyperopt = {\n",
    "    'n_neighbors': scope.int(hp.quniform('n_neighbors', 5, 25, 1)),\n",
    "    'method': hp.choice('method', ['largest', 'mean', 'median']),\n",
    "    'contamination': 79/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "KNN_inputs = {'classifier': KNN, 'param_space': KNN_param_hyperopt, 'num_eval': 3**2}\n",
    "hyperopt_inputs['KNN'] = KNN_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Isolation Forest (IForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "IF_param_hyperopt = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 10, 30, 1)),\n",
    "    'max_samples': scope.int(hp.quniform('max_samples', 10, 25, 1)),    \n",
    "    'max_features': 2, # since X has only 2 features, set it to 2\n",
    "    'contamination': 79/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "IF_inputs = {'classifier': IForest, 'param_space': IF_param_hyperopt, 'num_eval': 3**3}\n",
    "hyperopt_inputs['IForest'] = IF_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### One-Class Support Vector Machine (OCSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "OCSVM_param_hyperopt = {\n",
    "    'kernel': hp.choice('kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'nu': hp.uniform('nu', 0.1, 0.9),\n",
    "    'contamination': 79/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "OCSVM_inputs = {'classifier': OCSVM, 'param_space': OCSVM_param_hyperopt, 'num_eval': 3**2}\n",
    "hyperopt_inputs['OCSVM'] = OCSVM_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Comparison of Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d2_results_tuned = pd.DataFrame(columns=['algo', 'f1', 'precision', 'recall'])\n",
    "\n",
    "for algo, algo_inputs in hyperopt_inputs.items():\n",
    "    # run hyperopt\n",
    "    algo_hyperopt = hyperopt(algo_inputs['param_space'], \\\n",
    "                             X_d2, y_d2, \\\n",
    "                             algo_inputs['num_eval'], algo_inputs['classifier'])\n",
    "    # retrieve best parameters\n",
    "    algo_opt = algo_hyperopt[2]\n",
    "    algo_opt['f1'] = algo_hyperopt[1] # add f1 score\n",
    "    algo_opt['precision'] = algo_hyperopt[3]\n",
    "    algo_opt['recall'] = algo_hyperopt[4]\n",
    "    algo_opt['algo'] = algo # add algo name\n",
    "    # add to results dataframe\n",
    "    d2_results_tuned = d2_results_tuned.append(algo_opt, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d2_results_tuned[[\"algo\", \"recall\", \"precision\", \"f1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d2_results_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results with Tuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve float parameters\n",
    "cbof_lofub = d2_results_tuned.loc[1,\"lofub\"]\n",
    "cbof_pct = d2_results_tuned.loc[1,\"pct\"]\n",
    "OCSVM_nu = d2_results_tuned.loc[5,\"nu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model functions\n",
    "n_samples = len(y_d2)\n",
    "\n",
    "# dictionary of models & parameters to test\n",
    "# LOF, CBOF, ROCF are replications of Table 3 of the paper\n",
    "functions_dict = {\n",
    "    # LOF\n",
    "    'LOF (n=50)': { 'algo':'LOF', 'f':LOF(n_neighbors=20, algorithm=\"brute\", leaf_size=29,\n",
    "                                          contamination=50/n_samples) }, \n",
    "    'LOF (n=79)': { 'algo':'LOF', 'f':LOF(n_neighbors=20, algorithm=\"brute\", leaf_size=29,\n",
    "                                          contamination=79/n_samples) }, \n",
    "    'LOF (n=100)': { 'algo':'LOF', 'f':LOF(n_neighbors=20, algorithm=\"brute\", leaf_size=29,\n",
    "                                           contamination=100/n_samples) },\n",
    "    \n",
    "    # CBOF\n",
    "    'CBOF (n=50)': { 'algo':'CBOF', 'f':CBOF(k=14, pct=cbof_pct, lofub=cbof_lofub, contamination=50/n_samples) },\n",
    "    'CBOF (n=79)': { 'algo':'CBOF', 'f':CBOF(k=14, pct=cbof_pct, lofub=cbof_lofub, contamination=79/n_samples, ) },\n",
    "    'CBOF (n=100)': { 'algo':'CBOF', 'f':CBOF(k=14, pct=cbof_pct, lofub=cbof_lofub, contamination=100/n_samples) },\n",
    "    \n",
    "    # ROCF\n",
    "    'ROCF': { 'algo': 'ROCF', 'f':ROCF(distance_metric=\"euclidean\", k=12) },\n",
    "    \n",
    "    # KNN\n",
    "    'KNN (n=50)': { 'algo': 'KNN', 'f':KNN(method=\"mean\", n_neighbors=22, contamination=50/n_samples) },\n",
    "    'KNN (n=79)': { 'algo': 'KNN', 'f':KNN(method=\"mean\", n_neighbors=22, contamination=79/n_samples) },\n",
    "    'KNN (n=100)': { 'algo': 'KNN', 'f':KNN(method=\"mean\", n_neighbors=22, contamination=100/n_samples) },\n",
    "    \n",
    "    # IFOREST\n",
    "    'IForest (n=50)': { 'algo': 'IForest', 'f':IForest(max_samples=11, n_estimators=23, \n",
    "                                                       contamination=50/n_samples) },\n",
    "    'IForest (n=79)': { 'algo': 'IForest', 'f':IForest(max_samples=11, n_estimators=23,\n",
    "                                                       contamination=79/n_samples) },\n",
    "    'IForest (n=100)': { 'algo': 'IForest', 'f':IForest(max_samples=11, n_estimators=23, \n",
    "                                                        contamination=100/n_samples) },\n",
    "    \n",
    "    # OCSVM\n",
    "    'OCSVM (n=50)': { 'algo': 'OCSVM', 'f':OCSVM(kernel=\"rbf\", nu=OCSVM_nu, contamination=50/n_samples) },\n",
    "    'OCSVM (n=79)': { 'algo': 'OCSVM', 'f':OCSVM(kernel=\"rbf\", nu=OCSVM_nu, contamination=79/n_samples) },\n",
    "    'OCSVM (n=100)': { 'algo': 'OCSVM', 'f':OCSVM(kernel=\"rbf\", nu=OCSVM_nu, contamination=100/n_samples) },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output dataframe\n",
    "d2_final_results = pd.DataFrame(columns=['algo', 'outlier_rate', 'recall', 'precision', 'f1'])\n",
    "\n",
    "for name, f_dict in tqdm(functions_dict.items()):\n",
    "    # initialise classifier\n",
    "    clf = f_dict['f']\n",
    "\n",
    "    # fit classifier on data\n",
    "    clf.fit(X_d2)\n",
    "\n",
    "    # retrieve predictions\n",
    "    try:\n",
    "        y_pred = clf.get_outliers()\n",
    "    except:\n",
    "        y_pred = clf.labels_\n",
    "\n",
    "\n",
    "    # derive evaluation metrics\n",
    "    report = classification_report(y_true=y_d2, y_pred=y_pred, output_dict=True)['1']\n",
    "\n",
    "    row = { \n",
    "        'algo': f_dict['algo'], \n",
    "        'precision': report['precision'], 'recall': report['recall'], 'f1': report['f1-score']\n",
    "    }\n",
    "\n",
    "    # retrieve outlier rate\n",
    "    try:\n",
    "        row['outlier_rate'] = clf.get_outlier_rate()\n",
    "    except:\n",
    "        row['outlier_rate'] = clf.contamination\n",
    "\n",
    "    d2_final_results = d2_final_results.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Max ROCF from Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocf = ROCF(distance_metric=\"euclidean\", k=12)\n",
    "rocf.fit(X_d2)\n",
    "max_rocf = max(rocf.get_rocfs())\n",
    "print(max_rocf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Specification of Parameter k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_f1score = []\n",
    "k_value = []\n",
    "for k in tqdm(range(1, 31)):\n",
    "    # run rocf\n",
    "    rocf = ROCF(distance_metric=\"euclidean\", k=k)\n",
    "    \n",
    "    # fit rocf\n",
    "    rocf.fit(X_d2)\n",
    "    \n",
    "    # retrieve predictions\n",
    "    y_pred = rocf.get_outliers()\n",
    "\n",
    "    # derive evaluation metrics\n",
    "    report = classification_report(y_true=y_d2, y_pred=y_pred, output_dict=True)['1']\n",
    "    k_f1score.append(report[\"f1-score\"])\n",
    "    k_value.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(k_value, k_f1score, marker=\".\", color=\"darkblue\")\n",
    "plt.title('F1 Score against k (D2 dataset)')\n",
    "plt.xlabel('k, number of nearest neighbors')\n",
    "plt.ylabel('F1 Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Dataset D3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_d3, y_d3 = generate_synthetic_d3()\n",
    "color_d3 = [\"red\" if i == 1 else \"black\" for i in y_d3]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter([x[0] for x in X_d3], [x[1] for x in X_d3], c=color_d3, s=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate Parameters Suggested in Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model functions\n",
    "n_samples = len(y_d3)\n",
    "\n",
    "# dictionary of models & parameters to test\n",
    "# LOF, CBOF, ROCF are replications of Table 3 of the paper\n",
    "functions_dict = {\n",
    "    'LOF (k=10, n=10)': { 'algo': 'LOF', 'k':10, 'n':10, 'f':LOF(n_neighbors=10, contamination=10/n_samples) }, \n",
    "    'LOF (k=10, n=20)': { 'algo': 'LOF', 'k':10, 'n':20, 'f':LOF(n_neighbors=10, contamination=20/n_samples) },\n",
    "    'LOF (k=10, n=30)': { 'algo': 'LOF', 'k':10, 'n':30, 'f':LOF(n_neighbors=10, contamination=30/n_samples) },\n",
    "    'CBOF (k=5, alpha=0.99)': {'algo': 'CBOF', 'k': 5, 'n':3, 'f':CBOF(k=5, contamination=0.01, pct=0.2, lofub=1) },\n",
    "    'CBOF (k=5, alpha=0.90)': {'algo': 'CBOF', 'k': 5, 'n':31, 'f':CBOF(k=5, contamination=0.10, pct=0.2, lofub=1) },\n",
    "    'CBOF (k=5, alpha=0.85)': {'algo': 'CBOF', 'k': 5, 'n':46, 'f':CBOF(k=5, contamination=0.15, pct=0.2, lofub=1) },\n",
    "    'ROCF (k=10)': { 'algo': 'ROCF', 'k':10, 'n':None, 'f':ROCF(distance_metric=\"euclidean\", k=5) }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output dataframe\n",
    "d3_results = pd.DataFrame(columns=['algo', 'k', 'n', 'outlier_rate', 'recall', 'precision', 'f1'])\n",
    "\n",
    "for name, f_dict in tqdm(functions_dict.items()):\n",
    "    # initialise classifier\n",
    "    clf = f_dict['f']\n",
    "\n",
    "    # fit classifier on data\n",
    "    clf.fit(X_d3)\n",
    "\n",
    "    # retrieve predictions\n",
    "    try:\n",
    "        y_pred = clf.get_outliers()\n",
    "    except:\n",
    "        y_pred = clf.labels_\n",
    "\n",
    "\n",
    "    # derive evaluation metrics\n",
    "    report = classification_report(y_true=y_d3, y_pred=y_pred, output_dict=True)['1']\n",
    "\n",
    "    row = { \n",
    "        'algo': f_dict['algo'], 'k': f_dict['k'], 'n': f_dict['n'],\n",
    "        'precision': report['precision'], 'recall': report['recall'], 'f1': report['f1-score']\n",
    "    }\n",
    "\n",
    "    # retrieve outlier rate\n",
    "    try:\n",
    "        row['outlier_rate'] = clf.get_outlier_rate()\n",
    "    except:\n",
    "        row['outlier_rate'] = clf.contamination\n",
    "\n",
    "    d3_results = d3_results.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3_results[[\"algo\", \"outlier_rate\", \"recall\", \"precision\", \"f1\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_inputs = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter search range\n",
    "LOF_param_hyperopt = {\n",
    "    'n_neighbors': scope.int(hp.quniform('n_neighbors', 5, 15, 1)), \n",
    "    'algorithm': hp.choice('algorithm', ['ball_tree', 'kd_tree', 'brute']),\n",
    "    'leaf_size': scope.int(hp.quniform('leaf_size', 20, 40, 1)),\n",
    "    'contamination': 20/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "# num_eval proportional to number of combinations of parameter values for different models\n",
    "# num_eval = 3*(num_params_to_tune)\n",
    "LOF_inputs = {'classifier': LOF, 'param_space': LOF_param_hyperopt, 'num_eval': 3**3}\n",
    "hyperopt_inputs['LOF'] = LOF_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Based Outlier Factor (CBOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter search range\n",
    "CBOF_param_hyperopt = {\n",
    "    'k': scope.int(hp.quniform('n_neighbors', 3, 10, 1)),\n",
    "    'lofub': hp.uniform('lofub', 0.5, 5.0),\n",
    "    'pct': hp.uniform('pct', 0.2, 0.8),\n",
    "    'contamination': 20/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "CBOF_inputs = {'classifier': CBOF, 'param_space': CBOF_param_hyperopt, 'num_eval': 3**3}\n",
    "hyperopt_inputs['CBOF'] = CBOF_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Outlier Cluster Factor (ROCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter search range\n",
    "ROCF_param_hyperopt = {\n",
    "    'k': scope.int(hp.quniform('n_neighbors', 5, 10, 1))\n",
    "}\n",
    "\n",
    "ROCF_inputs = {'classifier': ROCF, 'param_space': ROCF_param_hyperopt, 'num_eval': 3**1}\n",
    "hyperopt_inputs['ROCF'] = ROCF_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_param_hyperopt = {\n",
    "    'n_neighbors': scope.int(hp.quniform('n_neighbors', 5, 15, 1)),\n",
    "    'method': hp.choice('method', ['largest', 'mean', 'median']),\n",
    "    'contamination': 20/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "KNN_inputs = {'classifier': KNN, 'param_space': KNN_param_hyperopt, 'num_eval': 3**2}\n",
    "hyperopt_inputs['KNN'] = KNN_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest (IForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IF_param_hyperopt = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 3, 20, 1)),\n",
    "    'max_samples': scope.int(hp.quniform('max_samples', 3, 20, 1)),    \n",
    "    'max_features': 2, # since X has only 2 features, set it to 2\n",
    "    'contamination': 20/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "IF_inputs = {'classifier': IForest, 'param_space': IF_param_hyperopt, 'num_eval': 3**3}\n",
    "hyperopt_inputs['IForest'] = IF_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Class Support Vector Machine (OCSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCSVM_param_hyperopt = {\n",
    "    'kernel': hp.choice('kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'nu': hp.uniform('nu', 0.1, 0.9),\n",
    "    'contamination': 20/n_samples # set to actual outlier % \n",
    "}\n",
    "\n",
    "OCSVM_inputs = {'classifier': OCSVM, 'param_space': OCSVM_param_hyperopt, 'num_eval': 3**2}\n",
    "hyperopt_inputs['OCSVM'] = OCSVM_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3_results_tuned = pd.DataFrame(columns=['algo', 'f1', 'precision', 'recall'])\n",
    "\n",
    "for algo, algo_inputs in hyperopt_inputs.items():\n",
    "    # run hyperopt\n",
    "    algo_hyperopt = hyperopt(algo_inputs['param_space'], \\\n",
    "                             X_d3, y_d3, \\\n",
    "                             algo_inputs['num_eval'], algo_inputs['classifier'])\n",
    "    # retrieve best parameters\n",
    "    algo_opt = algo_hyperopt[2]\n",
    "    algo_opt['f1'] = algo_hyperopt[1] # add f1 score\n",
    "    algo_opt['precision'] = algo_hyperopt[3]\n",
    "    algo_opt['recall'] = algo_hyperopt[4]\n",
    "    algo_opt['algo'] = algo # add algo name\n",
    "    # add to results dataframe\n",
    "    d3_results_tuned = d3_results_tuned.append(algo_opt, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d3_results_tuned[[\"algo\", \"recall\", \"precision\", \"f1\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results with Tuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve float parameters\n",
    "cbof_lofub = d3_results_tuned.loc[1,\"lofub\"]\n",
    "cbof_pct = d3_results_tuned.loc[1,\"pct\"]\n",
    "OCSVM_nu = d3_results_tuned.loc[5,\"nu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3_results_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model functions\n",
    "n_samples = len(y_d3)\n",
    "\n",
    "# dictionary of models & parameters to test\n",
    "# LOF, CBOF, ROCF are replications of Table 3 of the paper\n",
    "functions_dict = {\n",
    "    # LOF\n",
    "    'LOF (n=10)': { 'algo':'LOF', 'f':LOF(n_neighbors=9, algorithm=\"kd_tree\", leaf_size=30,\n",
    "                                                               contamination=10/n_samples) }, \n",
    "    'LOF (n=20)': { 'algo':'LOF', 'f':LOF(n_neighbors=9, algorithm=\"kd_tree\", leaf_size=30,\n",
    "                                                               contamination=20/n_samples) }, \n",
    "    'LOF (n=30)': { 'algo':'LOF', 'f':LOF(n_neighbors=9, algorithm=\"kd_tree\", leaf_size=30,\n",
    "                                                               contamination=30/n_samples) },\n",
    "    \n",
    "    # CBOF\n",
    "    'CBOF (n=10)': { 'algo':'CBOF', 'f':CBOF(k=3, pct=cbof_pct, lofub=cbof_lofub, \n",
    "                                                        contamination=10/n_samples) },\n",
    "    'CBOF (n=20)': { 'algo':'CBOF', 'f':CBOF(k=3, pct=cbof_pct, lofub=cbof_lofub,\n",
    "                                                        contamination=20/n_samples, ) },\n",
    "    'CBOF (n=30)': { 'algo':'CBOF', 'f':CBOF(k=3, pct=cbof_pct, lofub=cbof_lofub,\n",
    "                                                        contamination=30/n_samples) },\n",
    "    \n",
    "    # ROCF\n",
    "    'ROCF': { 'algo': 'ROCF', 'f':ROCF(distance_metric=\"euclidean\", k=6) },\n",
    "    \n",
    "    # KNN\n",
    "    'KNN (n=10)': { 'algo': 'KNN', 'f':KNN(method=\"largest\", n_neighbors=7, contamination=10/n_samples) },\n",
    "    'KNN (n=20)': { 'algo': 'KNN', 'f':KNN(method=\"largest\", n_neighbors=7, contamination=20/n_samples) },\n",
    "    'KNN (n=30)': { 'algo': 'KNN', 'f':KNN(method=\"largest\", n_neighbors=7, contamination=30/n_samples) },\n",
    "    \n",
    "    # IFOREST\n",
    "    'IForest (n=10)': { 'algo': 'IForest', 'f':IForest(max_samples=19, n_estimators=3, contamination=10/n_samples) },\n",
    "    'IForest (n=20)': { 'algo': 'IForest', 'f':IForest(max_samples=19, n_estimators=3, contamination=20/n_samples) },\n",
    "    'IForest (n=30)': { 'algo': 'IForest', 'f':IForest(max_samples=19, n_estimators=3, contamination=30/n_samples) },\n",
    "    \n",
    "    # OCSVM\n",
    "    'OCSVM (n=10)': { 'algo': 'OCSVM', 'f':OCSVM(kernel=\"rbf\", nu=OCSVM_nu, contamination=10/n_samples) },\n",
    "    'OCSVM (n=20)': { 'algo': 'OCSVM', 'f':OCSVM(kernel=\"rbf\", nu=OCSVM_nu, contamination=20/n_samples) },\n",
    "    'OCSVM (n=30)': { 'algo': 'OCSVM', 'f':OCSVM(kernel=\"rbf\", nu=OCSVM_nu, contamination=30/n_samples) },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output dataframe\n",
    "d3_final_results = pd.DataFrame(columns=['algo', 'outlier_rate', 'recall', 'precision', 'f1'])\n",
    "\n",
    "for name, f_dict in tqdm(functions_dict.items()):\n",
    "    # initialise classifier\n",
    "    clf = f_dict['f']\n",
    "\n",
    "    # fit classifier on data\n",
    "    clf.fit(X_d3)\n",
    "\n",
    "    # retrieve predictions\n",
    "    try:\n",
    "        y_pred = clf.get_outliers()\n",
    "    except:\n",
    "        y_pred = clf.labels_\n",
    "\n",
    "\n",
    "    # derive evaluation metrics\n",
    "    report = classification_report(y_true=y_d3, y_pred=y_pred, output_dict=True)['1']\n",
    "\n",
    "    row = { \n",
    "        'algo': f_dict['algo'], \n",
    "        'precision': report['precision'], 'recall': report['recall'], 'f1': report['f1-score']\n",
    "    }\n",
    "\n",
    "    # retrieve outlier rate\n",
    "    try:\n",
    "        row['outlier_rate'] = clf.get_outlier_rate()\n",
    "    except:\n",
    "        row['outlier_rate'] = clf.contamination\n",
    "\n",
    "    d3_final_results = d3_final_results.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3_final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Max ROCF from Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rocf = ROCF(distance_metric=\"euclidean\", k=6)\n",
    "rocf.fit(X_d3)\n",
    "max_rocf = max(rocf.get_rocfs())\n",
    "print(max_rocf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
